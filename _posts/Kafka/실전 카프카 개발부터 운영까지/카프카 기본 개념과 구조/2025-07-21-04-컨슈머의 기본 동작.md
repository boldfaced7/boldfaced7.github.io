---
layout: single
title: "4. 컨슈머의 기본 동작"
categories:
  - Kafka
  - 실전 카프카 개발부터 운영까지
  - 카프카 기본 개념과 구조
tags:
  - Kafka
  - 실전 카프카 개발부터 운영까지
  - 카프카 기본 개념과 구조
toc: true
toc_sticky: true
---
# 1. 컨슈머의 기본 동작

- 컨슈머는 카프카 토픽에 저장되어 있는 메시지를 가져옴
  - 이 때 내부적으로 컨슈머 그룹, 리밸런싱 등 여러 동작 수행



## 1. 컨슈머 그룹

![20241217_184136.png](/assets/images/Kafka/실전 카프카 개발부터 운영까지/카프카 기본 개념과 구조/04-컨슈머의 기본 동작/20241217_184136.png)

- 하나 이상의 컨슈머들이 모여 있는 그룹
    - 컨슈머는 반드시 컨슈머 그룹에 속해야

<br>

- 컨슈머 그룹은 각 파티션의 리더에게 메시지를 가져오기 위한 요청을 보냄



## 2. 컨슈머와 파티션 수

- 파티션 수와 컨슈머 수가 일대일로 매핑되는 것이 가장 이상적
- 컨슈머 수가 더 많다고, 처리량이 더 높아지지는 않음
- 장애 대비를 위한 스탠바이 컨슈머는 필요 없음
    - 컨슈머 장애 발생 시 리밸런싱을 통해 다른 컨슈머가 해당 컨슈머의 역할을 수행

<br>

# 2. 컨슈머 예제

## 1. `ConsumerAuto`: 오토 커밋

> - 오토 커밋 장점: 오프셋을 주기적으로 커밋해, 관리자의 오프셋 관리가 필요 없음
> - 오토 커밋 단점: 장애 발생 시 일부 메시지를 못 가져오거나 중복으로 가져올 수도
>



- `KafkaConfig`

```java
@Configuration
public class KafkaConfig {
	...
	@Bean
	public ConsumerFactory<String, Object> consumerFactory(
			KafkaProperties kafkaProperties) {
			
		return new DefaultKafkaConsumerFactory<>(Map.of(
				...
				// 오토 커밋 활성화
				ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "true",
				...
		));
	}
	...
}
```



- `ConsumerAuto`

```java
@Component
public class ConsumerAuto {

	@KafkaListener(
			topics = {"peter-basic01"}
	)
	public void listen(ConsumerRecords<String, String> records) {
		for (var record : records) {
			System.out.printf(
					"Topic: %s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
					record.topic(), record.partition(), 
					record.offset(), record.key(), record.value()
			);
		}
	}
}

```



## 2. `ConsumerSync`: 동기 오프셋 커밋

- 동기 오프셋 커밋: 메시지를 읽어 처리를 완료하고 현재 오프셋을 동기적으로 커밋
    > - 동기적 커밋: 커밋 완료를 기다림
    > - 속도는 느리지만 메시지 손실은 거의 발생하지 않음
    > - 메시지 손실: 토픽에는 메시지가 존재하나, 잘못된 오프셋 커밋으로 인한 위치 변경으로 컨슈머가 메시지를 가져오지 못하는 것

<br>

- 따라서 메시지가 손실되면 안 되는 작업은 동기 방식으로 진행해야



- `KafkaConfig`

```java
@Configuration
public class KafkaConfig {
	...
	@Bean
	public ConsumerFactory<String, Object> consumerFactory(
			KafkaProperties kafkaProperties) {
			
		return new DefaultKafkaConsumerFactory<>(Map.of(
				...
				// Kafka 클라이언트 수동 커밋 활성화
				ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false",
				...
		));
}

	@Bean
	public ConcurrentKafkaListenerContainerFactory<String, Object> 
			kafkaListenerContainerFactory(
					ConsumerFactory<String, Object> consumerFactory
	) {
		ConcurrentKafkaListenerContainerFactory<String, Object> factory
				= new ConcurrentKafkaListenerContainerFactory<>();
		
		factory.setConsumerFactory(consumerFactory);
		// spring-kafka 수동 커밋 활성화
		factory.getContainerProperties()
				.setAckMode(ContainerProperties.AckMode.MANUAL); 
		// 단일 Consumer 설정
		factory.setConcurrency(1);
		
		return factory;
	}
	...
}
```

- `ConsumerSync`

```java
@Component
public class ConsumerSync {

	@KafkaListener(
			topics = {"peter-basic01"},
			containerFactory = "kafkaListenerContainerFactory"
	)
	public void listen(ConsumerRecords<String, String> records, 
										 Acknowledgment acknowledgment
	) {
		for (var record : records) {
			System.out.printf(
					"Topic: %s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
					record.topic(), record.partition(), 
					record.offset(), record.key(), record.value()
			);
		}
		acknowledgment.acknowledge();
	}
}
```



## 3. `ConsumerAsync`: 비동기 오프셋 커밋

- 비동기 오프셋 커밋: 메시지를 읽어 처리를 완료하고 현재 오프셋을 비동기적으로 커밋
    - 비동기적 커밋: 커밋 완료를 기다리지 않음
    - 오프셋 커밋을 실패해도 재시도하지 않음

<br>

- 예) 10개의 메시지가 있고 오프셋 1-10번까지 순차적으로 커밋

    > 1. 1번 오프셋 메시지를 읽은 뒤, 1번 오프셋을 비동기 커밋
    >     - 마지막 오프셋: 1
    > 2. 2번 오프셋 메시지를 읽은 뒤, 2번 오프셋을 비동기 커밋하나, 실패
    >     - 마지막 오프셋: 1
    > 3. 3번 오프셋 메시지를 읽은 뒤, 3번 오프셋을 비동기 커밋하나, 실패
    >     - 마지막 오프셋: 1
    > 4. 4번 오프셋 메시지를 읽은 뒤, 4번 오프셋을 비동기 커밋하나, 실패
    >     - 마지막 오프셋: 1
    > 5. 5번 오프셋 메시지를 읽은 뒤, 5번 오프셋을 비동기 커밋
    >     - 마지막 오프셋: 5

    

    - 만약 실패 커밋을 재시도한다면, 오프셋 커밋으로 인한 중복 발생(5 → 2)
    - 이러한 이유로, 커밋 재시도를 하지 않음

<br>

- `ConsumerAsync`

```java
@Component
public class ConsumerAsync 
		implements BatchConsumerAwareMessageListener<String, String> {

	@Override
	@KafkaListener(
			topics = {"peter-basic01"},
			containerFactory = "kafkaListenerContainerFactory"
	)
	public void onMessage(
			ConsumerRecords<String, String> records, 
			Acknowledgment acknowledgment, 
			Consumer<String, String> consumer
	) {
			
		for (var record : records) {
			System.out.printf(
			"Topic: %s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
			record.topic(), record.partition(),
			record.offset(), record.key(), record.value()
			);
		}
		consumer.commitAsync();
	}
	
	@Override
	public void onMessage(
			List<ConsumerRecord<String, String>> list, 
			Consumer<?, ?> consumer
	) {...}
}

```