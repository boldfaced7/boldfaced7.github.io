---
layout: single
title: "5. 정확히 한 번 컨슈머 동작"
categories:
  - Kafka
  - 실전 카프카 개발부터 운영까지
  - 컨슈머의 내부 동작 원리와 구현
tags:
  - Kafka
  - 실전 카프카 개발부터 운영까지
  - 컨슈머의 내부 동작 원리와 구현
toc: true
toc_sticky: true
---
# 1. 트랜잭션 성공 메시지

1. **프로듀서**: 정확히 한 번 전송 성공
2. **트랜잭션 코디네이터**: 해당 레코드의 트랜잭션 성공을 표시하는 메시지를 추가 전송
3. **컨슈머**: 트랜잭션 코디네이터가 보낸 트랜잭션 성공 메시지를 수신한 레코드만 읽음

- 프로듀서의 메시지 전송 후 코디네이터의 메시지가 전송되므로, 오프셋은 +1이 아닌 +2

# 2. 정확히 한 번 컨슈머 구현

## 1. `ISOLATION_LEVEL_CONFIG`

- **트랜잭션 컨슈머**로 동작시키기 위한 설정
    - 트랜잭션 코디네이터와의 통신 없이, 트랜잭션이 완료된 메시지만 수신

- **`read_uncommitted`**(기본값): 모든 메시지를 읽을 수 있음
- **`read_committed`**: 트랜잭션이 완료된 메시지만 읽을 수 있음

## 2. `KafkaExactlyOnceConsumer`

```java
import static org.apache.kafka.clients.consumer.ConsumerConfig.*;

@Configuration
public class KafkaExactlyOnceConsumerConfig {

	@Bean
	public ConsumerFactory<String, Object> consumerFactory() {
		return new DefaultKafkaConsumerFactory<>(Map.of(
				BOOTSTRAP_SERVERS_CONFIG, "peter-kafka01.foo.bar:9092",
				KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class,
				VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class,
				GROUP_ID_CONFIG, "peter-consumer-01",
				AUTO_OFFSET_RESET_CONFIG, "earliest",
				ENABLE_AUTO_COMMIT_CONFIG, "false",
				// 정확히 한 번 전송을 위한 설정
				ISOLATION_LEVEL_CONFIG, "read_committed"
		));
	}
	
	@Bean
	public ConcurrentKafkaListenerContainerFactory<String, Object> 
			kafkaExactlyOnceConsumerListenerContainerFactory() {
			
		ConcurrentKafkaListenerContainerFactory<String, Object> factory
				= new ConcurrentKafkaListenerContainerFactory<>();
	
		factory.setConsumerFactory(consumerFactory());
		factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL);
	
		return factory;
	}
}
```

## 3. `ExactlyOnceConsumer`

```java
@Component
public class ExactlyOnceConsumer {

	@KafkaListener(
			topics = {"peter-test05"},
			containerFactory = "kafkaExactlyOnceConsumerListenerContainerFactory"
	)
	public void listen(
			ConsumerRecords<String, String> records, 
			Acknowledgment acknowledgment
		) {
		for (var record : records) {
			System.out.printf(
					"Topic: %s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
					record.topic(), record.partition(),
					record.offset(), record.key(), record.value()
			);
		}
		acknowledgment.acknowledge();
	}
}
```

## 4. 세그먼트 로그

```java
baseOffset: 0 lastOffset: 0 count: 1 baseSequence: 0 lastSequence: 0 producerId:
48000 **producerEpoch: 0** partitionLeaderEpoch: 0 isTransactional: true isControl: false position: 0 CreateTime: 1604742193088 size: 120 magic: 2 compresscodec: NONE crc:
2928040370 isvalid: true
| **offset: 0** CreateTime: 1604742193088 keysize: -1 valuesize: 52 sequence: 0 headerKeys: [] payload: Apache Kafka is a distributed streaming platform - 0

baseOffset: 1 lastOffset: 1 count: 1 baseSequence: -1 lastSequence: -1 producerId: 48000 producerEpoch: 0 partitionLeaderEpoch: 0 isTransactional: true isControl: true position: 120 CreateTime: 1604742193219 size: 78 magic: 2 compresscodec: NONE crc: 4095580164 isvalid: true
| **offset: 1** CreateTime: 1604742193219 keysize: 4 valuesize: 6 sequence: -1 headerKeys: [] endTxnMarker: COMMIT coordinatorEpoch: 0

baseOffset: 2 lastOffset: 2 count: 1 baseSequence: 0 lastSequence: 0 producerId:
48000 **producerEpoch: 1** partitionLeaderEpoch: 0 isTransactional: true isControl: false position: 198 CreateTime: 1604743999629 size: 120 magic: 2 compresscodec: NONE crc: 2161445190 isvalid: true
| **offset: 2** CreateTime: 1604743999629 keysize: -1 valuesize: 52 sequence: 0 headerKeys: [] payload: Apache Kafka is a distributed streaming platform - 0

baseOffset: 3 lastOffset: 3 count: 1 baseSequence: -1 lastSequence: -1 producerId: 48000 producerEpoch: 1 partitionLeaderEpoch: 0 isTransactional: true isControl: true position: 318 CreateTime: 1604743999719 size: 78 magic: 2 compresscodec: NONE crc: 2139765293 isvalid: true
| **offset: 3** CreateTime: 1604743999719 keysize: 4 valuesize: 6 sequence: -1 headerKeys: [] endTxnMarker: COMMIT coordinatorEpoch: 0
```

### `producerEpoch`: 0 → 1(1 증가)

- 비정상적인 좀비 프로듀서, 트랜잭션 실패 프로듀서를 방어하기 위한 동작
- ‘정확히 한 번’의 단계별 동작 중 프로듀서 초기화 단계에서 수행

### `offset`: 0 → 2(2 증가)

- 오프셋은 `producerEpoch`와 달리 2 증가
- 코디네이터의 트랜잭션 성공 메시지가 전송되었기 때문

# 3. 주의사항

## 1. 정확히 한 번만 가져오는가?

- 트랜잭션 컨슈머라고 정확히 한 번만 가져오는 것은 아님
    - **프로듀서**: 트랜잭션 코디네이터와 해당 트랜잭션의 정확한 처리 보장
    - **컨슈머**: 트랜잭션 코디네이터와 통신하지 않아, 정확한 처리 보장 불가
- 컨슈머가 정확히 한 번 메시지를 가져왔더라도, 해당 메시지가 다른 애플리케이션에 저장하는 과정에서 중복 처리될 수도
    - 컨슈머는 다른 싱크 저장소로 메시지들이 중복 저장되는 결과는 알 수 없음

## 2. 하나의 트랜잭션으로

- ‘정확히 한 번’ 처리가 가능하려면 ‘컨슘-메시지 처리-프로듀싱’이 한 트랜잭션으로 처리되어야
    - 해당 트랜잭션에서는 컨슈머 그룹의 오프셋 커밋을 트랜잭션에 포함
    - 만약 이 처리 과정에서 트랜잭션 실패 발생 시, 실패한 트랜잭션의 다시 시작이 가능

## 3. 카프카 커넥트 HDFS 커넥터