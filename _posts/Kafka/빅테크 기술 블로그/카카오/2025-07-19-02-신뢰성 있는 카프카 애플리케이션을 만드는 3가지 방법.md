# 02-신뢰성 있는 카프카 애플리케이션을 만드는 3가지 방법

> 출처: [신뢰성 있는 카프카 애플리케이션을 만드는 3가지 방법 - YouTube | kakao tech](https://www.youtube.com/watch?v=7_VdIFH6M6Q)
> 

# 0️⃣ 개요

## 이벤트 드리븐 아키텍처와 스트림 데이터 파이프라인

![](https://velog.velcdn.com/images/daehoon12/post/dada23f9-cb9a-4d50-8806-e753cd7d55ba/image.png)

- 카프카는 이벤트 드리븐 아키텍처, 스트림 데이터 파이프라인에서 중요한 역할을 수행
- 아파치 카프카는 스트림 이벤트를 다루기 적합하게 설계됨
    
    ---
    - 타임스탬프: 시간 단위 이벤트를 다루기 위해 사용
    - 파티션, 메시지 키: 순서 보장에 사용
    ---

- 이벤트 드리븐 아키텍처, 스트림 데이터 파이프라인에서는 네트워크 통신이 필수적으로 수반되므로, 메시지 전달의 신뢰성을 반드시 고려해야

## 메시지 전달 신뢰성

<aside>

- **정확히 한 번(Exaclty Once)**: 메시지가 한 번만 전달되는 가장 이상적인 상황
- **적어도 한 번(At Least Once)**: 브로커/네트워크 장애로 데이터가 중복 발행될 수 있음
- **최대 한 번(At Most Once)**: 브로커/네트워크 장애로 데이터가 유실될 수 있음
</aside>

- 보통 이벤트 드리븐 아키텍처, 스트림 데이터 파이프라인을 만들 때 ‘정확히 한 번’을 요구하는 비즈니스가 많음

# 1️⃣ 프로듀서의 메시지 전달 신뢰도

## ❓️ 문제: 레코드 중복 적재

<aside>

1. **프로듀서**: 레코드 전송
2. **브로커**: 레코드를 받고 `ACK`를 전달했으나, 네트워크 오류로 유실됨
3. **프로듀서**: 레코드 재전송(프로듀서 기본 옵션)
4. **브로커**: 레코드 중복 적재
</aside>

![](https://velog.velcdn.com/images/daehoon12/post/03ccd56d-9c25-4fd7-8ed5-fbc36b89a988/image.png)

## ❗️ 해결책: 멱등성 프로듀서 (Idempotence Producer)

- 프로듀서가 보내는 데이터의 중복 적재를 막기 위해 `enable.idempotence=true`로 설정
    
    ```java
    Properties configs = new Properties();
    
    configs.put(
    		ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, 
    		BOOTSTRAP_SERVERS
    );
    configs.put(
    		ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, 
    		StringSerializer.class.getName()
    );
    configs.put(
    		ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, 
    		StringSerializer.class.getName()
    );
    // 멱등성 프로듀서 옵션
    configs.put(
    		ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, 
    		true
    );
    KafkaProducer<String, String> producer = new KafkaProducer<>(config);
    ```
    
    - `enable.idempotence` 기본 값: `false`(< 3.0), `true`(≥ 3.0)

- 멱등성 프로듀서는 기본 프로듀서와 달리 레코드 전송 시. `pid`와 시퀀스 넘버를 함께 전달
- 브로커는 `pid`, `seq`를 이용해 중복 적재 요청을 구분

<aside>

1. **프로듀서**: 레코드, `pid`, `seq` 전송
2. **브로커**: 레코드를 받고 `ACK`를 전달했으나, 네트워크 오류로 유실됨
3. **프로듀서**: 레코드 재전송(프로듀서 기본 옵션)
4. **브로커**: 이미 적재된 동일 `pid`, `seq`의 레코드가 있다면 적재하지 않음
</aside>

![](https://velog.velcdn.com/images/daehoon12/post/eafa90b9-e32f-4e88-b730-9e7c23331603/image.png)

- 멱등성을 위한 필수 설정은 다음과 같음(미설정 시 `ConfigException` 발생)
    
    ---
    - `acks=all`: 프로듀서가 요청을 보내고 리더가 레플리카의 수신을 확인하는 개수
    - `enable.idempotence=true`: 레코드 쓰기 작업을 한 번만 허용할 것인지
    - `max.in.flight.requests.per.connection ≤ 5`: 한 번에 전송할 요청 개수
    - `retries > 0`: 레코드 재전송 횟수
    ---

- `acks` 설정은 `0` → `1` → `all`로 갈수록 메시지 전송의 신뢰성은 높아지지만, 응답 대기 시간이 늘어나 지연이 커짐
- `max.in.flight.requests.per.connection` 값이 클수록 처리량은 향상되나, 메시지 순서가 어긋날 수도
    - 배치 전송 중 일부 배치가 실패하면, 재전송된 배치가 나중에 도착해 메시지 순서가 뒤바뀜
    - `enable.itemoptence=true`로 설정하면, 전송 실패 시 이후 배치 전송을 중단하고, 실패 지점부터 재전송해 메시지 순서 유지

# 2️⃣ 토픽 간 연계(토픽 to 토픽 메시지 전달)

- 메시지를 받은 컨슈머가 프로듀서가 되어 메시지를 발행할 수도
    
    ![image.png](02-%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%AC%E1%84%89%E1%85%A5%E1%86%BC%20%E1%84%8B%E1%85%B5%E1%86%BB%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%8B%E1%85%A2%E1%84%91%E1%85%B3%E1%86%AF%E1%84%85%E1%85%B5%E1%84%8F%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%89%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%86%E1%85%A1%E1%86%AB%E1%84%83%E1%85%B3%E1%84%82%2023625f2f85d68133884ef709f6691bb4/81dc2941-cf2b-413d-8079-f98e25ad7d6f.png)
    

## 이벤트 드리븐 아키텍처 예시: 광고 CPC

- 사용자가 광고를 클릭하면, 광고주 비용 청구 로직과 매체사 CPC 수익 제공 로직이 동작해야
    
    ![image.png](02-%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%AC%E1%84%89%E1%85%A5%E1%86%BC%20%E1%84%8B%E1%85%B5%E1%86%BB%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%8B%E1%85%A2%E1%84%91%E1%85%B3%E1%86%AF%E1%84%85%E1%85%B5%E1%84%8F%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%89%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%86%E1%85%A1%E1%86%AB%E1%84%83%E1%85%B3%E1%84%82%2023625f2f85d68133884ef709f6691bb4/956e167a-8672-4c84-80fc-37bf466e261b.png)
    

## ❓️ 문제: 컨슈머 장애로 인한 이벤트 중복 전달

- 애플리케이션에서 광고 클릭 로그를 처리하고 커밋을 완료하기 전에 장애가 발생
    
    ![image.png](02-%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%AC%E1%84%89%E1%85%A5%E1%86%BC%20%E1%84%8B%E1%85%B5%E1%86%BB%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%8B%E1%85%A2%E1%84%91%E1%85%B3%E1%86%AF%E1%84%85%E1%85%B5%E1%84%8F%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%89%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%86%E1%85%A1%E1%86%AB%E1%84%83%E1%85%B3%E1%84%82%2023625f2f85d68133884ef709f6691bb4/image.png)
    

- 애플리케이션이 다시 동작할 때 이미 전달한 레코드를 중복 처리하게 됨

## ❗️ 해결책: 트랜잭션 프로듀서로 원자성 확보

- 트랜잭션을 사용해 토픽 간 연계 작업을 원자적으로 수행할 수 있음

- 프로듀서에 트랜잭선 설정을 적용하고 초기화한 뒤, 컨슈머와 프로듀서 로직을 함께 구성
    - 일반적으로는 컨슈머는 데이터를 처리한 후 오프셋을 커밋
    - 트랜잭션 프로듀서를 사용하면, 프로듀서가 `sendOffsetsToTransaction()`로 오프셋 커밋을 담당
    
    ```java
    // 트랜잭션 프로듀서 옵션
    procuerProps.put(
    		TRANSACTIONAL_ID_CONFIG, 
    		"AD_TRANSACTION"
    ); 
    
    // 트랜잭션 프로듀서 초기화
    producer.initTransactions();
    
    try {
    	while (true) {
    		ConsumerRecords<String, String> records = consumer.poll(
    				ofSeconds(10)
    		);
    		// records를 사용한 데이터 처리 생략
    		
    		producer.beginTransaction();
    		producer.send(new ProducerRecord<String, String>(
    				"다음 토픽", 
    				"처리가 완료된 이벤트"
    		));
    
    		// 컨슈머가 오프셋을 커밋하지 않고 프로듀서가 커밋을 수행
    		// 따라서 반드시 컨슈머의 enable.auto.commit은 false로 설정
    		producer.sendOffsetsToTransaction(
    				getRecordOffset(), 
    				CONSUMER_GROUP_ID
    		);
    		producer.commitTransaction();
    	}
    } catch (KafkaException e){
    	producer.abortTransaction();
    }
    ```
    

- 트랜잭션이 성공적으로 커밋될 때 오프셋도 함께 커밋되므로, 데이터 처리와 오프셋 커밋의 원자성이 보장됨
    
    ![](https://velog.velcdn.com/images/daehoon12/post/48afbaa6-0967-4167-b03c-602b6315fe04/image.png)
    
    - A 토픽 레코드 1개를 소비해, B 토픽에 레코드 2개를 발행하는 작업을 트랜잭션으로 묶음
    - 따라서 하나의 논리적 단위처럼 원자성 있게 처리 가능

- 트랜잭션이 커밋되지 않는 경우 B 토픽의 컨슈머가 해당 레코드를 읽을 수 없게 하려면,  `isolation.level`을 `read_committed`로 설정해야
    - 기본값 `read_uncommitted`은 트랜잭션 커밋 여부와 관계없이 모든 레코드를 읽음

# 3️⃣ 컨슈머의 중복 적재 방지

## ❓️ 문제: 데이터 적재와 오프셋 커밋 간의 트랜잭션 불일치

- 카프카 토픽에 있는 데이터를 가져와 DB에 적재하는 상황을 가정
- 토픽 간 연계처럼 커밋과 프로듀서를 하나의 트랜잭션으로 묶는 방식이 이상적
- DB 종류가 다른 경우, DB 적재와 오프셋 커밋을 하나의 트랜잭션으로 묶는 것은 사실상 불가능
    
    ![image.png](02-%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%AC%E1%84%89%E1%85%A5%E1%86%BC%20%E1%84%8B%E1%85%B5%E1%86%BB%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%8B%E1%85%A2%E1%84%91%E1%85%B3%E1%86%AF%E1%84%85%E1%85%B5%E1%84%8F%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%89%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%86%E1%85%A1%E1%86%AB%E1%84%83%E1%85%B3%E1%84%82%2023625f2f85d68133884ef709f6691bb4/image%201.png)
    

## ❗️ 해결책 (1): 유니크 키를 활용한 멱등성 컨슈머

- Timestamp, UUID와 같은 데이터로 유니크 키를 만들어 중복 적재를 방지
    
    ![](https://velog.velcdn.com/images/daehoon12/post/b483250c-561b-42c1-b2b0-e8113002efdc/image.png)
    

- 토픽에는 데이터가 중복으로 적재되지만, DB에 저장되는 데이터 중복은 막을 수 있음
- 유니크 키를 지원하는 DB(Oracle, MySQL)에 데이터를 넣을 때 적합

## ❗️ 해결책 (2): Upsert를 활용한 멱등성 컨슈머

- 적재 시 중복되는 데이터가 있으면 Update, 없으면 Insert
    
    ![](https://velog.velcdn.com/images/daehoon12/post/fa4958c9-2be2-4e36-b4d1-cb94af355c56/image.png)
    

- MongoDB, 어플리케이션 레벨에서의 JPA(`save()`)가 upsert를 지원

## ❗️ 해결책 (3): Write-ahead Log를 활용한 컨슈머

- Log file, WAL file을 비교해 중복 적재를 방지
    
    ---
    - **Log file**: 트랜잭션 발생 전에 Log를 미리 기록
    - **WAL file**: 트랜잭션 커밋 후 데이터를 어디까지 적재했는지 기록
    ---
    ![](https://velog.velcdn.com/images/daehoon12/post/b08216c9-6fbd-46fd-82c3-8a347351cc1f/image.png)
    

- 레코드 오프셋 관리 로직과 데이터 확인 로직이 필요해, 로직이 복잡해짐

# 4️⃣ 활용 사례: 스마트 메시지 서비스

- 타켓 최적화를 통해 특정 유저에게 적합한 광고를 전송하는 서비스
    
    ![](https://velog.velcdn.com/images/daehoon12/post/bcc8ace4-bf7e-4c3e-ad2e-ac91f42fb93f/image.png)
    

- 이벤트를 각각 처리하는 것이 아니라 **Tumbling Window Aggregation**로 묶어서 일정 주기마다 모델링 계산을 해 타겟팅을 생성
    
    ![](https://velog.velcdn.com/images/daehoon12/post/3cb300a9-072a-4a96-b851-8eb2cd583315/image.png)
    

- Upsert 방식으로 중복 컨슈머의 중복 적재를 방지
    
    ```java
    // Key에 해당하는 레코드를 Tumbling Window 기간동안 Count
    KTable<Window<String>, Long> reactionTable = mapByKeyReaction
    		.groupByKey()
        .windowedBy(WINDOW_DURATION_TIME)
        .count();
    
    // 중복 적재를 막기 위해서 Window에 대응하는 Key를 메시지 키에 주입
    KStream<ReactionWindowKey, Long> aggregatedReaction = reactionTable
    		.toStream()
    		.map((windowedId, value) -> {
    				// ...
    				return new KeyValue<>(key, value);  
    		});
    
    aggregatedReaction.forEach(((key, value) -> {
    		// MongoDB Document 생성 생략
    		
    		UpsertOptions options = new UpdateOptions().upsert(true);
    
    		// upsert 수행
    		UpdateResult result = collection.updateOne(query, updates, options);
    }));
    ```
    

# 5️⃣ 정리

<aside>

1. **Idempotence Producer**: 레코드 A Topic 레코드 중복 적재 방지
2. **Transaction Consumer & Producer**: B Topic 레코드 중복 적재 방지
3. **Unique Key, Upsert, WAL Consumer**: 데이터 중복 저장 방지
</aside>

![](https://velog.velcdn.com/images/daehoon12/post/f42521eb-aa1b-43b3-8c82-1cddd2ac6d81/image.png)