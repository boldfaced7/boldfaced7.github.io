---
layout: single
title: "1. 우리 팀은 카프카를 어떻게 사용하고 있을까"
categories:
  - Kafka
  - 빅테크 기술 블로그
  - 우아한형제들
tags:
  - Kafka
  - 빅테크 기술 블로그
  - 우아한형제들
toc: true
toc_sticky: true[](https://www.youtube.com/watch?v=xpwRTu47fqY
---


> **출처**: [**우리 팀은 카프카를 어떻게 사용하고 있을까 - 우아한형제들 기술블로그**](https://techblog.woowahan.com/17386/)

<br>

# 0️⃣ 개요

## 1. 카프카 개요

- 카프카는 분산 스트리밍 플랫폼으로, 대량의 데이터 처리와 실시간 전송에 사용
- 모든 데이터는 로그 형식으로 파일 시스템에 기록됨
    - 로그는 추가만 가능하며, 시간 순으로 정렬된 데이터 흐름(레코드 시퀀스)

- 로그를 한 곳에 모아 처리하도록 중앙 집중화되어 있으며, 대용량 데이터를 수집하고 실시간 스트리밍으로 소비가 가능
  

<br>

![image.png](/assets/images/Kafka/빅테크 기술 블로그/우아한형제들/01-우리 팀은 카프카를 어떻게 사용하고 있을까/image.png)

> - **토픽**: 데이터의 주제를 나타내며, 이름으로 분리된 로그
>     - 메시지를 보낼 때는 특정 토픽을 지정
>
>
> <br>
>
> - **파티션**: 토픽은 하나 이상의 파티션으로 나누어질 수 있으며, 각 파티션은 순서가 있는 연속된 메시지의 로그
>     - 파티션은 병렬 처리를 지원하고, 데이터의 분산 및 복제를 관리
>
> <br>
>
> - **레코드**: 데이터의 기본 단위로 키/값 구성
> - **오프셋**: 특정 파티션 내의 레코드 위치를 식별하는 값
> - **프로듀서**: 메시지를 생성하고 특정 토픽으로 전달
> - **컨슈머**: 특정 토픽의 메시지를 가져와 처리
> - **컨슈머 그룹**: 여러 개의 컨슈머 인스턴스를 그룹화해, 특정 토픽의 파티션을 공유
>     - 컨슈머 그룹마다 오프셋을 가지고 있어, 같은 소스에서 여러 컨슈머 그룹이 개별적으로 소비
>     - 데이터를 병렬로 처리하고 처리량을 증가시킴
>
> <br>
>
> - **카프카 커넥터**: 카프카와 외부 시스템을 연동 시 쉽게 연동 가능하도록 하는 프레임워크
>     - MySQL, S3 등 다양한 프로토콜과 연동을 지원
>     - **소스 커넥터**: 메시지 발행과 관련 있는 커넥터
>     - **싱크 커넥터**: 메시지 소비와 관련 있는 커넥터

<br>

## 2. 딜리버리서비스 팀에서 활용하는 방식

- 딜리버리서비스 팀은 하루 100만 건 이상 생성되는 배민배달을 중계
    - 여러 주문 서비스의 배민배달을 받아 배달 서비스 중 하나로 분배
    - 배민배달의 배달 과정을 중계/관리


<br>

- 분산 시스템 이벤트 기반 아키텍처로 주문/배달을 처리하며, 카프카는 팀의 주요 기술 중 하나

- 딜리버리서비스 팀의 분산 서버 구조는 다음과 같음

    ![image.png](/assets/images/Kafka/빅테크 기술 블로그/우아한형제들/01-우리 팀은 카프카를 어떻게 사용하고 있을까/image%201.png)

    > - **주문/배달 서버**: 주문 이벤트를 받아 배달 프로세스를 관리
    > - **분석 서버**: 발행한 이벤트를 기반으로 분석
    
    - 처리량을 높이고 성능을 향상시키기 위해, 서버 그룹은 N개의 여러 서버로 구성됨

<br>

# 1️⃣ **안전한 주문-배달 처리**

- **목표**: 주문 발생 시, 배달이 완료될 때까지 안전하게 처리


- **이벤트 순서 보장**: 카프카를 이벤트 브로커로 사용해 주문/배달 이벤트 순서를 보장
- **데이터 정합성 확보**: 분산 시스템에서 메시지 전송을 하나의 트랜잭션으로 관리
    - 순서를 보장한 재시도를 통해 이벤트 누락이 없도록 처리

<br>

## **순서 보장**

### 전체 배달 프로세스

![image.png](/assets/images/Kafka/빅테크 기술 블로그/우아한형제들/01-우리 팀은 카프카를 어떻게 사용하고 있을까/image%202.png)

<br>

### ❓ 문제: 거의 동시에 발생하는 이벤트

- 배달이 진행되면서 여러 이벤트가 순서대로 발행됨
- 특정 이벤트는 거의 동시에 발생하기도 하고, 배달 상태를 변경하기도
- 따라서 배달 프로세스 관리를 위해 이벤트 발행 관련 순서 보장이 중요

- `배차완료`와 거의 동시에 `픽업준비요청`이 발생하면, 다음 상황이 발생할 수도
  
    > - **프로듀서**: `배차완료` 이후 `픽업준비요청`을 발행
    > - **컨슈머**: 네트워크 등의 이슈로 `픽업준비요청` 이후, `배차완료`를 수신
    > - 이 때 순서가 보장되지 않으면 컨슈머의 비즈니스 로직 처리에 문제가 발생

<br>

### ❗ 해결책: 카프카의 메시지 소비 순서 보장

- 카프카는 메시지 발행 순서에 따라 소비할 수 있도록 순서를 보장
  
  - 순서 관리가 필요한 식별자를 키로 관리하여 순서를 보장
  
    > - 한 카프카 클러스터에 여러 토픽을 구성할 수 있음
    > - 한 토픽은 여러 개의 파티션으로 구성됨
    > - 키가 같은 메시지는 같은 파티션으로 할당됨
    > - 한 파티션에 하나의 컨슈머가 할당됨
    > - 따라서 키가 같은 메시지는 같은 서버가 소비해 이벤트 순서가 보장됨
    




- 메시지 공급자가 발행 순서를 보장해, 거의 비슷한 시점에 발행되는 메시지 동시성 이슈 발생 상황을 줄일 수 있음

<br>

## **데이터 정합성 확보**

### ❓ 문제: 데이터는 저장되었으나, 이벤트는 발행되지 않음

- DB에는 변경된 배달 상태가 저장되었으나 이벤트는 발행되지 않을 수도
  
    >
    > - `주문취소`로 `배달취소`가 발생
    > - **DB**: 해당 배달은 취소된 상태(`배달취소`)로 저장됨
    > - **카프카**: 이벤트 발행에 실패
    > - 취소된 배달이 진행됨


- 데이터와 메시지 발행의 트랜잭션을 하나로 관리하여 데이터 정합성을 확보해야
- 메시지 발행에 실패하는 경우, 메시지 누락 방지를 위해 재시도가 필요
    - 재시도 과정에서도 메시지의 순서는 보장되어야
    - 하지만, 다른 비즈니스 이벤트 처리에 미치는 영향은 최소화해야

 <br>

### ❗ 해결책: Transactional Outbox Pattern

- 분산 시스템에서 DB 트랜잭션과 메시지 브로커를 조합해, 데이터 일관성과 메시지 전송의 원자성을 보장하는 패턴
- 이 패턴의 핵심 아이디어는 다음과 같음

>
> 1. 트랜잭션 DB에 `OUTBOX` 테이블을 도입해, 트랜잭션 완료 시 변경 사항을 기록
> 2. `OUTBOX` 테이블에 새로운 레코드가 추가될 때마다 변경 사항을 메시지로 전송
>

<br>

### Debezium

- Debezium: DB의 변경 사항을 감지해 이벤트 스트림으로 변환하는 오픈 소스 라이브러리
    - DB의 기록인 `binlog`의 변경 사항을 감지하여 읽는 로그 테일링 기법을 사용
    - 변경 사항을 순서대로 읽어, 설정한 토픽으로 전달

- Debezium의 MySQL source connector는 태스크를 하나만 사용하도록 강제해, 단일 커넥터에서 메시지 전송 순서를 보장

<br>

### ❓ 문제: 메시지 지연

- Debezium의 MySQL source connector는 하나의 태스크로 동작
- 따라서 커넥터 처리 속도가 테이블에 데이터가 쌓이는 속도보다 느리면 메시지 지연이 발생

<br>

### ❗ 해결책: 토픽별 테이블 분리

>
> - 토픽별로 `OUTBOX` 테이블을 분리
> - 각 `OUTBOX` 테이블은 식별자 기반으로 여러 개의 테이블로 구성
> - 각 테이블에 커넥터를 연결해, 한 커넥터가 처리하는 양을 분산
>

![image.png](/assets/images/Kafka/빅테크 기술 블로그/우아한형제들/01-우리 팀은 카프카를 어떻게 사용하고 있을까/image%203.png)


- `OUTBOX` 테이블에 저장된 순서대로 이벤트 메시지 발행을 보장하도록 Debezium을 설정
- 같은 키는 같은 테이블에 저장되며, 한 테이블에서는 한 커넥터를 사용해 같은 키에 대해서는 순서를 보장

<br>

# 2️⃣ **이벤트 버스로 활용**


- 카프카를 이벤트 버스로 활용해 분산 시스템에 알림

<br>

## ❓ 문제: 서버군 값 관리

- 한 서버에서 값을 변경하면 서버군에 속한 모든 서버의 변경된 값을 관리해야 하는 경우가 존재

>
> - 배달 서버는 배달 서비스 분배 규칙을 인 메모리로 관리
> - 운영자가 분배 규칙을 변경하면, 배달 서버는 변경을 반영
>

<br>

## ❗ 해결책: `RemoteApplicationEvent`와 카프카

- 스프링 클라우드의 `RemoteApplicationEvent`를 사용하여 카프카를 이벤트 버스로 사용
- 이를 통해, 값 관리가 필요한 서버군에 변경된 값을 알리고, 변경 내용을 반영하도록 관리
  

    > - 이벤트 버스 토픽을 설정하고, id는 고유하게 `${서버명}:${식별자}` 형식으로 설정
    > - `RemoteApplicationEvent`를 상속한 이벤트에 목적지 서버군을 명시해 발행
    > - 이벤트 버스는 목적지 서버군에 이벤트를 전달
    

    ![image.png](/assets/images/Kafka/빅테크 기술 블로그/우아한형제들/01-우리 팀은 카프카를 어떻게 사용하고 있을까/image%204.png)

- `RemoteApplicationEvent`를 상속한 `DeliveryServiceRemoteApplicationEvent`를 추상 클래스로 설정하고, 각 특성에 맞게 구현체를 구성
  
    ```java
    public abstract class DeliveryServiceRemoteApplicationEvent 
    		extends RemoteApplicationEvent {
    
    	protected DeliveryServiceRemoteApplicationEvent(String destination) {
    		super(
    				SOURCE, 
    				ORIGIN, 
    				DESTINATION_FACTORY.getDestination(destination)
    		);
    	}
    }
    ```
    
    ```java
    	// 분배 규칙 CustomRemoteEvent
    	public class RouteRuleRemoteEvent 
    			extends DeliveryServiceRemoteApplicationEvent {
    	
    		public RouteRuleRemoteEvent() {
    			super("delivery"); // destination: 배달 서버
    		}
    	}
    ```
    
    - 서버들이 인메모리로 저장하고 있는 값을 초기화나 변경이 필요한 경우에 사용
    
- 분배 규칙이 변경된 경우, 배달 서버군에 변경 사항이 반영되도록 `RemoteApplicationEvent`를 발행/소비
  
    ```java
    public void load() {
    	routeRuleSetStore.load();
    	remoteApplicationEventPublisher.publishEvent(
    			new RouteRuleRemoteEvent()
    	);
    }
    ```
    
    ```java
    @EventListener
    public void handle(RouteRuleRemoteEvent event) {
    	routeRuleSetStore.load();
    }
    ```
    

## 딜리버리서비스 팀의 이벤트 버스

- 딜리버리서비스 팀은 이벤트 버스 토픽을 한 파티션으로 관리
  

    > - 설정 값 변경에는 높은 처리량이 필요하지 않음
    > - 같은 서버군은 같은 변경 사항을 수신해야
    > - 파티션이 여러 개인 경우, 순서 보장이 어려움
    


- 모든 인스턴스가 동일한 이벤트를 수신해야 하므로, 모든 서버에 다른 컨슈머 그룹 ID를 할당
    - 카프카에서는 같은 컨슈머 그룹 ID를 가진 인스턴스 중 하나만 이벤트를 소비하기 때문

<br>

- 스프링 클라우드는 별도의 컨슈머 그룹 ID를 명시하지 않으면 `anonymous.{UUID}` 형식의 ID를 할당
    - 서버 인스턴스마다 고유한 그룹 ID가 설정되므로, 모든 서버가 동일 이벤트를 개별 소비

<br>

- 모니터링 및 관리 효율성을 위해, `anonymous` 프리픽스 그룹은 필터링 대상으로 분류

<br>

# 3️⃣ **배달 정보 집계**


- 분석에 적합하게 가공된 형태로 데이터를 제공
- 카프카 스트림즈로 실시간 배달 정보를 집계해 배달 상황 파악

<br>

## ❓ 문제: 실시간 데이터 반영

- 배치를 사용해 분석 데이터를 제공하면, 실시간 데이터를 반영하기 어려움
- 실시간으로 배달 현황을 파악하고 서비스에 반영하기 위해, 카프카 스트림즈를 활용

## ❗ 해결책: 카프카 스트림즈

- 메시지를 활용한 실시간 집계/분석 시스템으로 실시간 데이터 스트리밍 및 분석 시스템에 적합
- 카프카 스트림즈 애플리케이션은 데이터의 흐름을 처리
  

    > - 전처리 단계와 스트림 연결로 데이터 스트림을 입력 받아 필요한 처리 수행
    > - 새로운 스트림을 생성해 데이터를 처리하고 결과를 산출
    


<br>

## **분석용으로 가공한 데이터 제공**

### 비즈니스/분석 토픽 분리

- 분석 서버에서는 다음 작업을 수행 
    > - 배달 이벤트를 수신
    > - 전처리 과정을 거쳐 조회하기 편한 형태로 가공
    > - 분석 토픽으로 이벤트 재발행



- 원본 토픽과 분석용 토픽을 분리하여 사용
    - 각 토픽에 문제가 발행해도, 영향 범위를 분리해 관리
    - 토픽 특성에 맞는 리소스를 사용하고 조정할 수 있도록 구성

<br>

### 배달 이벤트를 통합 배달 이벤트로

- 배달은 생성, 배차, 픽업, 완료 등의 순서로 진행되며, 특정 행위마다 배달 이벤트를 발행
- 분석 시, 개별 배달 이벤트가 아니라 배달 건별로 정리된 정보를 확인하고 싶은 경우가 많음
- 분석하기 편하도록 배달 한 건에 발생한 이벤트를 모아서 제공

- 다음 과정을 거져 종합 데이터를 생성/발행
  

    > 1. 원본 배달 토픽에서 `배달생성` 이벤트를 수신
    > 2. Redis에 주요한 주문, 배달 정보 저장
    > 3. 배달 진행에 따라 발행된 이벤트를 수신
    > 4. 각 배달 이벤트의 주요한 정보를 업데이트
    > 5. 의미 있는 정보로 구성한 새로운 통합 배달 이벤트를 분석 토픽에 발행
    > 6. S3 싱크 커넥터로, 발행한 이벤트를 AWS S3 객체 저장소에 영구 저장
    > 7. 완료된 배달은 Redis에서 삭제


<br>

- 이벤트 영구 저장소와 비즈니스 로직 처리를 위한 저장소를 분리해, 분석/비즈니스 서비스의 상호 영향을 최소화
- S3 객체저장소에 저장된 데이터는 [AWS Athena](https://aws.amazon.com/ko/athena/)를 사용해 비즈니스 서비스 저장소에 부하를 주지 않고 오래된 기록까지 조회할 수 있음

  ![image.png](/assets/images/Kafka/빅테크 기술 블로그/우아한형제들/01-우리 팀은 카프카를 어떻게 사용하고 있을까/image%205.png)


<br>

## **실시간 데이터 제공**

- 스트림즈 애플리케이션을 활용해 실시간 배달 데이터를 집계

> 1. 분석용 배달 토픽에 들어온 레코드 흐름으로 최신 배달 상태 집계(최신 배달 상태 저장소)
>     - 키: 배달 식별자, 값: 배달 데이터
> 2. 최신 배달을 기준으로 배달 상태별 건수 집계(배달 상태별 집계 저장소)
>     - 키: 배달 상태, 값: 배달 상태별 건수
> 3. 배달 상태별 개수를 조회하는 그라파나 게이지를 등록해, 조회 결과를 대시보드로 시각화
>
>     ![image.png](/assets/images/Kafka/빅테크 기술 블로그/우아한형제들/01-우리 팀은 카프카를 어떻게 사용하고 있을까/image%206.png)
>



- 다양하게 집계되는 데이터를 활용해 유용한 기능 제공 가능
  
    >
    > - 실시간으로 이상 상황 감지를 자동화해, 알람으로 빠르게 장애 상황 인지
    > - 큰 장애로 번지기 전에 주문유입을 최소화하여 장애 범위를 최소화
